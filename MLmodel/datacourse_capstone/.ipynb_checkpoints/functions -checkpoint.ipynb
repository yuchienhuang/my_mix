{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import dill\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import simplejson as json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.parse import quote\n",
    "from urllib.request import urlopen\n",
    "import spotipy\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "client_credentials_manager = spotipy.oauth2.SpotifyClientCredentials('d6967ce2057448d4aab3ad9898119c97',  'ad7f82cc26a64f1595b6b3c4cd917243')\n",
    "spotify = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_Feat(artists):\n",
    "    pos = artists.find('Featuring')\n",
    "    if pos == -1:\n",
    "        return artists\n",
    "    else:\n",
    "        return artists[:pos].strip()\n",
    "    \n",
    "def get_track_artists(year, domain = 'https://www.billboard.com/charts/year-end/'):\n",
    "    path = domain + str(year) + '/hot-100-songs'\n",
    "    response = requests.get(path)\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "    parents = soup.findAll(class_=r'ye-chart-item__text')\n",
    "\n",
    "    track_artists = []\n",
    "    for parent in parents:\n",
    "        track = parent.find('div',attrs={'class':'ye-chart-item__title'}).get_text().strip()\n",
    "        artists = parent.find('div',attrs={'class':'ye-chart-item__artist'}).get_text().strip()\n",
    "        track_artists.append((track, artists))\n",
    "    return track_artists\n",
    "\n",
    "\n",
    "def get_album_artists(year, domain='https://www.billboard.com/archive/charts/'):\n",
    "    response = requests.get(domain + str(year) + \"/top-album-sales\")\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    table = soup.find('table',attrs={'class':'archive-table'}).findAll('tr')[1:]\n",
    "\n",
    "    album_artists=[]\n",
    "    for tr in table:\n",
    "        td = tr.findAll('td')\n",
    "        try:\n",
    "            album_artists.append((td[-2].get_text(),td[-1].get_text()))\n",
    "        except:\n",
    "            pass\n",
    "    return album_artists\n",
    "\n",
    "def get_track_artists_arxiv(year, domain='https://www.billboard.com/archive/charts/'):\n",
    "    path = domain + str(year) + '/hot-100'\n",
    "    response = requests.get(path)\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "    table = soup.find('table',attrs={'class':'archive-table'}).findAll('tr')[1:]\n",
    "\n",
    "    track_artists=[]\n",
    "    for tr in table:\n",
    "        td = tr.findAll('td')\n",
    "        try:\n",
    "            track_artists.append((td[-2].get_text(),td[-1].get_text()))\n",
    "        except:\n",
    "            pass\n",
    "    return track_artists\n",
    "\n",
    "def get_album_id_from_track(track, artists):\n",
    "    try:\n",
    "        track = track.replace(\"'\",'')\n",
    "        artists = \", \".join(re.split(r' & | x | X | With | with ', artists))\n",
    "        q = 'track:' + track + ' artist:' + artists\n",
    "        result = spotify.search(q, limit=1)\n",
    "        the_first_album = result['tracks']['items'][0]['album']\n",
    "        album_id = the_first_album.get('id')\n",
    "        return album_id\n",
    "    except:\n",
    "#         try:\n",
    "#             artists = ' '.join(artists.split(' x '))\n",
    "#             artists = ' '.join(artists.split(' X '))\n",
    "#             q = track + ' ' + artists\n",
    "#             result = spotify.search(q, limit=1)\n",
    "#             the_first_album = result['tracks']['items'][0]['album']\n",
    "#             album_id = the_first_album.get('id')\n",
    "#             return album_id\n",
    "#         except:\n",
    "        return track, artists\n",
    "\n",
    "def get_album_id_from_album(album, artists):\n",
    "\n",
    "    try:\n",
    "        album = album.replace(\"'\",'')        \n",
    "        artists = \", \".join(re.split(r' & | x | X | With | with ', artists))\n",
    "        q = 'album:' + album + ' artist:' + artists\n",
    "        result = spotify.search(q, type='album', limit=1)\n",
    "        the_first_album = result['albums']['items'][0]\n",
    "        album_id = the_first_album.get('id')\n",
    "        return album_id\n",
    "    \n",
    "    except:\n",
    "#         try:\n",
    "#             q =  album\n",
    "#             result = spotify.search(q, type='album', limit=1)\n",
    "#             the_first_album = result['albums']['items'][0]\n",
    "#             album_id = the_first_album.get('id')\n",
    "#             return album_id\n",
    "#         except:\n",
    "        return album, artists\n",
    "\n",
    "def get_albums_id_list(year, get_album_id_func, scraping_func):\n",
    "    albums_id = []    \n",
    "\n",
    "\n",
    "    trackOrAlbum_artists = scraping_func(year)\n",
    "    for trackOrAlbum, artists in trackOrAlbum_artists:\n",
    "        albums_id.append(get_album_id_func(trackOrAlbum,strip_Feat(artists)))\n",
    "        \n",
    "    return albums_id\n",
    "\n",
    "def album_json(d):\n",
    "    subkeys = ['id', 'name', 'genres',  'popularity', 'total_tracks']\n",
    "    \n",
    "    album_info = {k: d[k] for k in subkeys if k in d}\n",
    "    tracks = d['tracks']['items']\n",
    "    tracks_id = [t['id'] for t in tracks]\n",
    "    tracks_df_json = pd.DataFrame(audio_features(tracks_id),columns=['id',  'track_number', 'popularity','name', 'duration_ms', 'tempo','time_signature', 'key',\n",
    "       'valence', 'mode', 'acousticness', 'danceability', 'energy', \n",
    "       'instrumentalness',  'liveness', 'loudness', 'speechiness']).to_json(orient='split')\n",
    "    album_info.update({'artists_list': [a['name'] for a in d['artists']], 'tracks_info': tracks_df_json })\n",
    "    \n",
    "    return album_info\n",
    "\n",
    "def track_json(track_id):\n",
    "    d = spotify.track(track_id)\n",
    "    subkeys = ['id', 'popularity', 'name', 'track_number']\n",
    "    subdict = {k: d[k] for k in subkeys if k in d}\n",
    "    return subdict\n",
    "\n",
    "\n",
    "def audio_feature_decorator(spotify_audio_features_func):\n",
    "\n",
    "    def wrapper_func(track_id_list):\n",
    "        subkeys = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature']\n",
    "        \n",
    "        \n",
    "        features_list = spotify_audio_features_func(track_id_list)\n",
    "        \n",
    "        my_features_list = []\n",
    "        for i, features in enumerate(features_list):\n",
    "            sub_features = {k: features[k] for k in subkeys if k in features}\n",
    "            other_info = track_json(track_id_list[i])\n",
    "            other_info.update(sub_features)\n",
    "            \n",
    "            my_features_list.append(other_info)\n",
    "            \n",
    "        return my_features_list\n",
    "    \n",
    "    return wrapper_func\n",
    "\n",
    "@audio_feature_decorator\n",
    "def audio_features(track_id_list):\n",
    "    return spotify.audio_features(track_id_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(album_json):\n",
    "    \n",
    "    tracks_df = pd.read_json(album_json['tracks_info'], orient='split')\n",
    "\n",
    "    return {k: album_json[k] for k in ['id', 'name', 'genres', 'popularity', 'total_tracks', 'artists_list']}, tracks_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Album(object):\n",
    "#     def __init__(self, album_json):\n",
    "        \n",
    "#         self.id, self.name, self.genres, self.popularity, self.total_tracks, self.artists_list = [album_json[k] for k in ['id', 'name', 'genres', 'popularity', 'total_tracks', 'artists_list']]\n",
    "        \n",
    "#         self.tracks_df = pd.read_json(album_json['tracks_info'], orient='split')\n",
    "\n",
    "#     def transform_features_(self):\n",
    "        \n",
    "#         cst = ColumnSelectTransformer(['acousticness', 'danceability', 'energy', 'liveness', 'speechiness','valence'])\n",
    "#         poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "#         feat_matrix = poly.fit_transform(cst.transform(self.tracks_df))\n",
    "#         min_max_scaler = MinMaxScaler()\n",
    "        \n",
    "#         return min_max_scaler.fit_transform(feat_matrix)\n",
    "     \n",
    "#     def transform_duration_tempo_(self):\n",
    "        \n",
    "#         return np.hstack((self.tracks_df[['duration_ms']].values/1e4, self.tracks_df[['tempo']]))\n",
    "\n",
    "    \n",
    "#     def transform_track_numbers_(self):\n",
    "#         tnt = TrackNumberTransFormer()\n",
    "#         return tnt.transform(self.tracks_df)\n",
    "    \n",
    "#     def transform_key_(self):\n",
    "#         one_hot_key_matrix = np.zeros((self.total_tracks,12))\n",
    "#         for i, k in enumerate(self.tracks_df['key']):\n",
    "#             one_hot_key_matrix[i, k] = 1\n",
    "\n",
    "\n",
    "        \n",
    "#         return one_hot_key_matrix\n",
    "        \n",
    "#     def transform_labels_(self):\n",
    "#         sorted_popularity = sorted(self.tracks_df['popularity'].values,reverse=True)\n",
    "#         try:\n",
    "\n",
    "#             the_first = sorted_popularity[0]\n",
    "#             the_second = sorted_popularity[1]\n",
    "#             the_last = sorted_popularity[-1]\n",
    "#             shift_by = min(self.popularity, the_second)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             shifted_popularity = self.tracks_df['popularity'].values - shift_by\n",
    "#             transformed_popularity = np.zeros(self.total_tracks,dtype=np.float)\n",
    "\n",
    "#     #         for i, t in enumerate(shifted_popularity):\n",
    "#     #             if t < 0:\n",
    "\n",
    "#     #                 transformed_popularity[i] =  t/ self.total_tracks\n",
    "#     #             else:\n",
    "#     #                 transformed_popularity[i] = t\n",
    "#             for i, t in enumerate(shifted_popularity):\n",
    "#                 if t < 0:\n",
    "\n",
    "#                     transformed_popularity[i] =  - t / (the_last - shift_by)\n",
    "#                 else:\n",
    "#                     transformed_popularity[i] = t / (the_first - shift_by)\n",
    "\n",
    "#             #print('before: ',sorted(self.tracks_df['popularity'].values,reverse=True))                \n",
    "#             #print('after: ', sorted(transformed_popularity,reverse=True))        \n",
    "\n",
    "\n",
    "#             return transformed_popularity\n",
    "#         except:\n",
    "#             popularity = self.popularity\n",
    "#             popularity_list = self.tracks_df['popularity'].values\n",
    "            \n",
    "#             if len(sorted_popularity) == 2:\n",
    "#                 l, s = sorted_popularity\n",
    "\n",
    "#                 if l <= popularity:\n",
    "#                     print(popularity_list - popularity,popularity,s)\n",
    "#                     transformed_popularity = (popularity_list - popularity) / (popularity-s)\n",
    "#                 elif s >= popularity:\n",
    "#                     transformed_popularity = (popularity_list - popularity) / (l-popularity)\n",
    "\n",
    "\n",
    "#                 else:\n",
    "#                     norm_by = max(l-popularity, popularity-s)\n",
    "#                     transformed_popularity = (popularity_list - popularity)/ norm_by\n",
    "\n",
    "#             else:\n",
    "#                 c = sorted_popularity[0]\n",
    "#                 if c > popularity:\n",
    "#                     transformed_popularity =  0.5 * np.ones(len(popularity_list))\n",
    "#                 elif c < popularity: \n",
    "#                     transformed_popularity =  -0.5 * np.ones(len(popularity_list))\n",
    "#                 else:\n",
    "#                     transformed_popularity =  np.zeros(len(popularity_list))\n",
    "\n",
    "\n",
    "#             return transformed_popularity\n",
    "\n",
    "#     def transform(self):\n",
    "#         return np.hstack((self.transform_track_numbers_(), self.transform_key_(), self.transform_duration_tempo_())), self.transform_features_(), self.transform_labels_()\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_songs_albums_year(year, get_album_id_func, scraping_func):\n",
    "    json_list = []\n",
    "    wrong_queries = []\n",
    "    time_out = []\n",
    "    albums_id_list = get_albums_id_list(year, get_album_id_func, scraping_func)\n",
    "    for album_id in albums_id_list:\n",
    "        try:\n",
    "            result = spotify.album(album_id)\n",
    "            json_list.append(album_json(result))\n",
    "        except:\n",
    "            if type(album_id) == tuple:\n",
    "                wrong_queries.append(album_id)\n",
    "            else:\n",
    "                try:\n",
    "                    time.sleep(6)\n",
    "                    result = spotify.album(album_id)\n",
    "                    json_list.append(album_json(result))\n",
    "                except:\n",
    "                    time_out.append(album_id)\n",
    "    fail = []\n",
    "    for album_id in time_out:\n",
    "        try:\n",
    "            result = spotify.album(album_id)\n",
    "            json_list.append(album_json(result))\n",
    "            \n",
    "        except:\n",
    "            fail.append(album_id)\n",
    "\n",
    "    \n",
    "        \n",
    "    return json_list, (year, fail, wrong_queries)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(2018,[(\"God's Plan\", 'Drake'), (\"Boo'd Up\", 'Ella Mai'), ('Bodak Yellow (Money Moves)', 'Cardi B'), (\"King's Dead\", 'Jay Rock, Kendrick Lamar, Future, James Blake'), ('Te Bote', 'Casper Magico, Nio Garcia, Darell, Nicky Jam, Ozuna, Bad Bunny'), ('Lemon', 'N*E*R*D, Rihanna'), (\"I'm Upset\", 'Drake')]),\n",
    "(2017, [(\"I'm The One\", 'DJ Khaled'), (\"There's Nothing Holdin' Me Back\", 'Shawn Mendes'), ('Bodak Yellow (Money Moves)', 'Cardi B'), (\"Can't Stop The Feeling!\", 'Justin Timberlake'), ('Broccoli', 'D.R.A.M.')]),\n",
    " (2016,[(\"Don't Let Me Down\", 'The Chainsmokers'), (\"Can't Stop The Feeling!\", 'Justin Timberlake'), ('Broccoli', 'D.R.A.M.'), (\"Don't\", 'Bryson Tiller'), (\"Don't Mind\", 'Kent Jones'), (\"Ex's & Oh's\", 'Elle King'), (\"Can't Feel My Face\", 'The Weeknd')]),\n",
    " (2015, [(\"Can't Feel My Face\", 'The Weeknd'), (\"I'm Not The Only One\", 'Sam Smith'), ('G.D.F.R.', 'Flo Rida'), ('B**** Better Have My Money', 'Rihanna'), (\"Ex's & Oh's\", 'Elle King'), ('Tuesday', 'I LOVE MAKONNEN'), (\"Don't\", 'Ed Sheeran')]),\n",
    " (2014,[(\"Don't Tell 'Em\", 'Jeremih'), (\"Ain't It Fun\", 'Paramore'), (\"Don't\", 'Ed Sheeran'), (\"Can't Remember To Forget You\", 'Shakira')]),\n",
    " (2013,[(\"Can't Hold Us\", 'Macklemore, Ryan Lewis'), ('Holy Grail', 'Jay Z'), (\"Don't You Worry Child\", 'Swedish House Mafia'), ('Die Young', 'Ke$ha'), (\"That's My Kind Of Night\", 'Luke Bryan'), (\"Mama's Broken Heart\", 'Miranda Lambert'), (\"I'm Different\", '2 Chainz')]),\n",
    " (2012,[(\"Don't Wake Me Up\", 'Chris Brown'), (\"Let's Go\", 'Calvin Harris'), ('Die Young', 'Ke$ha')]),\n",
    " (2011,[(\"What's My Name?\", 'Rihanna'), (\"I'm On One\", 'DJ Khaled'), (\"Don't You Wanna Stay\", 'Jason Aldean, Kelly Clarkson'), ('Remind Me', 'Brad Paisley Duet, Carrie Underwood'), (\"Don't Wanna Go Home\", 'Jason Derulo')]),\n",
    " (2010,[('TiK ToK', 'Ke$ha'), ('Empire State Of Mind', 'Jay-Z + Alicia Keys'), (\"Haven't Met You Yet\", 'Michael Buble'), ('Young Forever', 'Jay-Z + Mr. Hudson'), ('Blah Blah Blah', 'Ke$ha'), ('Eenie Meenie', 'Sean Kingston, Justin Bieber')]),\n",
    " (2009,[(\"Don't Trust Me\", '3OH!3'), ('Run This Town', 'Jay-Z, Rihanna, Kanye West'), ('Empire State Of Mind', 'Jay-Z + Alicia Keys'), ('Turn My Swag On', \"Soulja Boy Tell'em\"), ('People Are Crazy', 'Billy Currington')]),\n",
    " (2008,[(\"Don't Stop The Music\", 'Rihanna'), (\"Can't Believe It\", 'T-Pain'), (\"It's Not My Time\", '3 Doors Down'), ('Crank That (Soulja Boy)', \"Soulja Boy Tell'em\"), (\"Can't Help But Wait\", 'Trey Songz'), (\"You're Gonna Miss This\", 'Trace Adkins')]),\n",
    " (2007,[(\"Don't Matter\", 'Akon'), (\"It's Not Over\", 'Daughtry'), ('Crank That (Soulja Boy)', \"Soulja Boy Tell'em\"), (\"Cupid's Chokehold/Breakfast In America\", 'Gym Class Heroes'), (\"I'm A Flirt\", 'R. Kelly Or Bow Wow ('), ('Go Getta', 'Young Jeezy'), ('Same Girl', 'R. Kelly Duet, Usher')]),\n",
    " (2006,[(\"You're Beautiful\", 'James Blunt'), (\"It's Goin' Down\", 'Yung Joc'), ('Snap Yo Fingers', 'Lil Jon'), (\"Ain't No Other Man\", 'Christina Aguilera'), (\"I'm N Luv (Wit A Stripper)\", 'T-Pain'), (\"Where'd You Go\", 'Fort Minor'), (\"Don't Forget About Us\", 'Mariah Carey'), (\"What's Left Of Me\", 'Nick Lachey'), ('Soul Survivor', 'Young Jeezy'), (\"I'm Sprung\", 'T-Pain')])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2018,\n",
       "  [],\n",
       "  [('M A N I A', 'Fall Out Boy'),\n",
       "   ('My Dear Melancholy, (EP)', 'The Weeknd'),\n",
       "   ('Mamma Mia! Here We Go Again', 'Soundtrack')]),\n",
       " (2017,\n",
       "  [],\n",
       "  [('Moana', 'Soundtrack'),\n",
       "   ('The Search For Everything : Wave One (EP)', 'John Mayer'),\n",
       "   ('4:44', 'JAY-Z')]),\n",
       " (2016,\n",
       "  [],\n",
       "  [('Lemonade', 'Beyonce'),\n",
       "   ('Lemonade', 'Beyonce'),\n",
       "   ('Suicide Squad: The Album', 'Soundtrack')]),\n",
       " (2015,\n",
       "  [],\n",
       "  [('NOW 53', 'Various Artists'),\n",
       "   ('Pitch Perfect 2', 'Soundtrack'),\n",
       "   ('Descendants', 'Soundtrack')]),\n",
       " (2014,\n",
       "  [],\n",
       "  [('Frozen', 'Soundtrack'),\n",
       "   ('Frozen', 'Soundtrack'),\n",
       "   ('NOW 49', 'Various Artists'),\n",
       "   ('Frozen', 'Soundtrack'),\n",
       "   ('Frozen', 'Soundtrack'),\n",
       "   ('Guardians Of The Galaxy: Awesome Mix Vol. 1', 'Soundtrack')]),\n",
       " (2013,\n",
       "  [],\n",
       "  [('Les Miserables', 'Soundtrack'),\n",
       "   ('Magna Carta... Holy Grail', 'JAY-Z'),\n",
       "   ('The Marshall Mathers LP 2', 'Eminem'),\n",
       "   ('The Marshall Mathers LP 2', 'Eminem'),\n",
       "   ('Blame It All On My Roots: Five Decades Of Influences', 'Garth Brooks')]),\n",
       " (2012,\n",
       "  [],\n",
       "  [('The Hunger Games: Songs From District 12 And Beyond', 'Soundtrack'),\n",
       "   ('NOW 43', 'Various Artists')]),\n",
       " (2011,\n",
       "  [],\n",
       "  [('NOW 37', 'Various Artists'),\n",
       "   ('Never Say Never: The Remixes (EP)', 'Justin Bieber'),\n",
       "   ('Hell: The Sequel (EP)', 'Bad Meets Evil'),\n",
       "   ('Watch The Throne', 'Jay Z Kanye West')]),\n",
       " (2010,\n",
       "  [],\n",
       "  [('Animal', 'Ke$ha'),\n",
       "   ('Hope For Haiti Now', 'Various Artists'),\n",
       "   ('Glee: The Music, The Power Of Madonna (EP)', 'Soundtrack'),\n",
       "   ('Glee: The Music, Volume 3: Showstoppers:', 'Soundtrack'),\n",
       "   ('Glee: The Music, Journey To Regionals (EP)', 'Soundtrack')]),\n",
       " (2009,\n",
       "  [],\n",
       "  [('Hannah Montana: The Movie', 'Soundtrack'),\n",
       "   ('Losos Way (Soundtrack)', 'Fabolous'),\n",
       "   ('The Blueprint 3', 'JAY-Z'),\n",
       "   ('The Twilight Saga: New Moon', 'Soundtrack'),\n",
       "   ('Michael Jacksons This Is It (Soundtrack)', 'Michael Jackson')]),\n",
       " (2008,\n",
       "  [],\n",
       "  [('Juno', 'Soundtrack'),\n",
       "   ('E=MC2', 'Mariah Carey'),\n",
       "   ('Mamma Mia!', 'Soundtrack'),\n",
       "   ('The Recession', 'Young Jeezy')]),\n",
       " (2007,\n",
       "  [],\n",
       "  [('Dreamgirls', 'Soundtrack'),\n",
       "   ('NOW 24', 'Various Artists'),\n",
       "   ('Hannah Montana 2 (Soundtrack)/Meet Miley Cyrus', 'Miley Cyrus'),\n",
       "   ('High School Musical 2', 'Soundtrack'),\n",
       "   ('American Gangster', 'JAY-Z')]),\n",
       " (2006,\n",
       "  [],\n",
       "  [('Curious George (Soundtrack)', 'Jack Johnson'),\n",
       "   ('High School Musical', 'Soundtrack'),\n",
       "   ('High School Musical', 'Soundtrack'),\n",
       "   ('10,000 Days', 'Tool'),\n",
       "   ('Testimony: Vol. 1, Life & Relationship (Bonus Track Edition)',\n",
       "    'India.Arie'),\n",
       "   ('NOW 22', 'Various Artists'),\n",
       "   ('LeToya', 'LeToya'),\n",
       "   ('NOW 22', 'Various Artists'),\n",
       "   ('Hannah Montana', 'Soundtrack'),\n",
       "   ('NOW 23', 'Various Artists'),\n",
       "   ('Kingdom Come', 'JAY-Z'),\n",
       "   ('Ciara: The Evolution', 'Ciara'),\n",
       "   ('The Inspiration', 'Young Jeezy')]),\n",
       " (2005,\n",
       "  [],\n",
       "  [('Be As You Are: Songs From An Old Blue Chair', 'Kenny Chesney'),\n",
       "   ('X&Y', 'Coldplay'),\n",
       "   ('Now 19', 'Various Artists'),\n",
       "   ('#1s', \"Destiny's Child\")]),\n",
       " (2004,\n",
       "  [],\n",
       "  [('D12 World', 'D12'),\n",
       "   ('Stardust... The Great American Songbook Vol. III', 'Rod Stewart'),\n",
       "   ('Unfinished Business', 'R. Kelly, Jay-Z'),\n",
       "   ('MTV Ultimate Mash-Ups Presents: Collision Course', 'Jay-Z/Linkin Park')]),\n",
       " (2003,\n",
       "  [],\n",
       "  [('8 Mile', 'Soundtrack'),\n",
       "   ('Bad Boys II', 'Soundtrack'),\n",
       "   ('Greatest Hits Volume II And Some Other Stuff', 'Alan Jackson'),\n",
       "   ('The Neptunes Present... Clones', 'Various Artists'),\n",
       "   ('Shockn YAll', 'Toby Keith'),\n",
       "   ('The Black Album', 'JAY-Z'),\n",
       "   ('The Black Album', 'JAY-Z')]),\n",
       " (2002,\n",
       "  [],\n",
       "  [('O Brother, Where Art Thou?', 'Soundtrack'),\n",
       "   ('Juslisen (Just Listen)', 'Musiq'),\n",
       "   ('P. Diddy & Bad Boy Records Present... We Invented The Remix',\n",
       "    'Various Artists'),\n",
       "   ('Elv1s: 30 #1 Hits', 'Elvis Presley'),\n",
       "   ('8 Mile', 'Soundtrack'),\n",
       "   ('The Blueprint 2: The Gift And The Curse', 'JAY-Z')]),\n",
       " (2001,\n",
       "  [],\n",
       "  [('Survivor', \"Destiny's Child\"),\n",
       "   ('Lateralus', 'Tool'),\n",
       "   ('Celebrity', \"'N Sync\"),\n",
       "   ('The Blueprint', 'JAY-Z'),\n",
       "   ('Scarecrow', 'Garth Brooks')]),\n",
       " (2000,\n",
       "  [],\n",
       "  [('Vol. 3... Life And Times Of S. Carter', 'JAY-Z'),\n",
       "   ('Voodoo', \"D'Angelo\"),\n",
       "   ('No Strings Attached', \"'N Sync\"),\n",
       "   ('G.O.A.T. Featuring James T. Smith: The Greatest Of All Time',\n",
       "    'LL Cool J'),\n",
       "   ('The Dynasty Roc La Familia (2000 -- )', 'JAY-Z')])]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fail_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_list_2 = []\n",
    "for year in reversed(range(2000,2006)):\n",
    "    data, fail = top_songs_albums_year(year,get_album_id_from_track,get_track_artists_arxiv)\n",
    "    fail_list_2.append(fail)\n",
    "    with open('top_songs_albums_v3_year_{}'.format(year),'w') as outfile:\n",
    "        json.dump(data,outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...3secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n"
     ]
    }
   ],
   "source": [
    "fail_list = []\n",
    "for year in reversed(range(2000,2019)):\n",
    "    data, fail = top_songs_albums_year(year,get_album_id_from_album)\n",
    "    fail_list.append(fail)\n",
    "    with open('best_seller_albums_v3_year_{}'.format(year),'w') as outfile:\n",
    "        json.dump(data,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "2018 [] [(\"God's Plan\", 'Drake'), (\"Boo'd Up\", 'Ella Mai'), ('Bodak Yellow (Money Moves)', 'Cardi B'), (\"King's Dead\", 'Jay Rock, Kendrick Lamar, Future, James Blake'), ('Te Bote', 'Casper Magico, Nio Garcia, Darell, Nicky Jam, Ozuna, Bad Bunny'), ('Lemon', 'N*E*R*D, Rihanna'), (\"I'm Upset\", 'Drake')]\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "2017 [] [(\"I'm The One\", 'DJ Khaled'), (\"There's Nothing Holdin' Me Back\", 'Shawn Mendes'), ('Bodak Yellow (Money Moves)', 'Cardi B'), (\"Can't Stop The Feeling!\", 'Justin Timberlake'), ('Broccoli', 'D.R.A.M.')]\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "2016 [] [(\"Don't Let Me Down\", 'The Chainsmokers'), (\"Can't Stop The Feeling!\", 'Justin Timberlake'), ('Broccoli', 'D.R.A.M.'), (\"Don't\", 'Bryson Tiller'), (\"Don't Mind\", 'Kent Jones'), (\"Ex's & Oh's\", 'Elle King'), (\"Can't Feel My Face\", 'The Weeknd')]\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "2015 [] [(\"Can't Feel My Face\", 'The Weeknd'), (\"I'm Not The Only One\", 'Sam Smith'), ('G.D.F.R.', 'Flo Rida'), ('B**** Better Have My Money', 'Rihanna'), (\"Ex's & Oh's\", 'Elle King'), ('Tuesday', 'I LOVE MAKONNEN'), (\"Don't\", 'Ed Sheeran')]\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "2014 [] [(\"Don't Tell 'Em\", 'Jeremih'), (\"Ain't It Fun\", 'Paramore'), (\"Don't\", 'Ed Sheeran'), (\"Can't Remember To Forget You\", 'Shakira')]\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "2013 [] [(\"Can't Hold Us\", 'Macklemore, Ryan Lewis'), ('Holy Grail', 'Jay Z'), (\"Don't You Worry Child\", 'Swedish House Mafia'), ('Die Young', 'Ke$ha'), (\"That's My Kind Of Night\", 'Luke Bryan'), (\"Mama's Broken Heart\", 'Miranda Lambert'), (\"I'm Different\", '2 Chainz')]\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "2012 [] [(\"Don't Wake Me Up\", 'Chris Brown'), (\"Let's Go\", 'Calvin Harris'), ('Die Young', 'Ke$ha')]\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "2011 [] [(\"What's My Name?\", 'Rihanna'), (\"I'm On One\", 'DJ Khaled'), (\"Don't You Wanna Stay\", 'Jason Aldean, Kelly Clarkson'), ('Remind Me', 'Brad Paisley Duet, Carrie Underwood'), (\"Don't Wanna Go Home\", 'Jason Derulo')]\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "2010 [] [('TiK ToK', 'Ke$ha'), ('Empire State Of Mind', 'Jay-Z + Alicia Keys'), (\"Haven't Met You Yet\", 'Michael Buble'), ('Young Forever', 'Jay-Z + Mr. Hudson'), ('Blah Blah Blah', 'Ke$ha'), ('Eenie Meenie', 'Sean Kingston, Justin Bieber')]\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "2009 [] [(\"Don't Trust Me\", '3OH!3'), ('Run This Town', 'Jay-Z, Rihanna, Kanye West'), ('Empire State Of Mind', 'Jay-Z + Alicia Keys'), ('Turn My Swag On', \"Soulja Boy Tell'em\"), ('People Are Crazy', 'Billy Currington')]\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "2008 [] [(\"Don't Stop The Music\", 'Rihanna'), (\"Can't Believe It\", 'T-Pain'), (\"It's Not My Time\", '3 Doors Down'), ('Crank That (Soulja Boy)', \"Soulja Boy Tell'em\"), (\"Can't Help But Wait\", 'Trey Songz'), (\"You're Gonna Miss This\", 'Trace Adkins')]\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "2007 [] [(\"Don't Matter\", 'Akon'), (\"It's Not Over\", 'Daughtry'), ('Crank That (Soulja Boy)', \"Soulja Boy Tell'em\"), (\"Cupid's Chokehold/Breakfast In America\", 'Gym Class Heroes'), (\"I'm A Flirt\", 'R. Kelly Or Bow Wow ('), ('Go Getta', 'Young Jeezy'), ('Same Girl', 'R. Kelly Duet, Usher')]\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...4secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "retrying ...3secs\n",
      "retrying ...1secs\n",
      "2006 [] [(\"You're Beautiful\", 'James Blunt'), (\"It's Goin' Down\", 'Yung Joc'), ('Snap Yo Fingers', 'Lil Jon'), (\"Ain't No Other Man\", 'Christina Aguilera'), (\"I'm N Luv (Wit A Stripper)\", 'T-Pain'), (\"Where'd You Go\", 'Fort Minor'), (\"Don't Forget About Us\", 'Mariah Carey'), (\"What's Left Of Me\", 'Nick Lachey'), ('Soul Survivor', 'Young Jeezy'), (\"I'm Sprung\", 'T-Pain')]\n"
     ]
    }
   ],
   "source": [
    "for year in reversed(range(2006,2019)):\n",
    "    data = top_songs_albums_year(year,get_album_id_from_track)\n",
    "    with open('top_songs_albums_v3_year_{}'.format(year),'w') as outfile:\n",
    "        json.dump(data,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(year):\n",
    "\n",
    "    with open(\"best_seller_albums_v3_year_\" + str(year)) as json_file:  \n",
    "        best_seller_albums_data = json.load(json_file)\n",
    "        best_seller_albums_albums = [Album(d) for d in best_seller_albums_data]\n",
    "\n",
    "    with open(\"top_songs_albums_v3_year_\" + str(year)) as json_file:  \n",
    "        top_songs_albums_data = json.load(json_file)\n",
    "        top_songs_albums_albums = [Album(d) for d in top_songs_albums_data]\n",
    "\n",
    "    return best_seller_albums_albums, top_songs_albums_albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = album_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Album(object):\n",
    "    def __init__(self, album_json):\n",
    "        \n",
    "        self.id, self.name, self.genres, self.popularity, self.total_tracks, self.artists_list = [album_json[k] for k in ['id', 'name', 'genres', 'popularity', 'total_tracks', 'artists_list']]\n",
    "        \n",
    "        self.tracks_df = pd.read_json(album_json['tracks_info'], orient='split')\n",
    "\n",
    "    def transform_features_(self):\n",
    "        \n",
    "        cst = ColumnSelectTransformer(['acousticness', 'danceability', 'energy', 'liveness', 'speechiness','valence'])\n",
    "        poly = PolynomialFeatures(interaction_only=False, include_bias=True)\n",
    "        feat_matrix = poly.fit_transform(cst.transform(self.tracks_df))\n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        \n",
    "        return min_max_scaler.fit_transform(feat_matrix)\n",
    "     \n",
    "    def transform_duration_tempo_(self):\n",
    "        \n",
    "        return np.hstack((self.tracks_df[['duration_ms']].values/1e4, self.tracks_df[['tempo']]))\n",
    "\n",
    "    \n",
    "    def transform_track_numbers_(self):\n",
    "        tnt = TrackNumberTransFormer()\n",
    "        return tnt.transform(self.tracks_df)\n",
    "    \n",
    "    def transform_key_(self):\n",
    "        one_hot_key_matrix = np.zeros((self.total_tracks,12))\n",
    "        for i, k in enumerate(self.tracks_df['key']):\n",
    "            one_hot_key_matrix[i, k] = 1\n",
    "\n",
    "\n",
    "        \n",
    "        return one_hot_key_matrix\n",
    "        \n",
    "    def transform_labels_(self):\n",
    "        #return self.tracks_df['popularity'].values\n",
    "        sorted_popularity = sorted(np.unique(self.tracks_df['popularity'].values),reverse=True)\n",
    "        try:\n",
    "            the_first = sorted_popularity[0]\n",
    "            the_second = sorted_popularity[1]\n",
    "            the_last = sorted_popularity[-1]\n",
    "            shift_by = min(self.popularity, the_second)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            shifted_popularity = self.tracks_df['popularity'].values - shift_by\n",
    "            transformed_popularity = np.zeros(self.total_tracks,dtype=np.float)\n",
    "\n",
    "    #         for i, t in enumerate(shifted_popularity):\n",
    "    #             if t < 0:\n",
    "\n",
    "    #                 transformed_popularity[i] =  t/ self.total_tracks\n",
    "    #             else:\n",
    "    #                 transformed_popularity[i] = t\n",
    "\n",
    "\n",
    "\n",
    "            for i, t in enumerate(shifted_popularity):\n",
    "                if t < 0:\n",
    "\n",
    "                    transformed_popularity[i] =  - t / (the_last - shift_by)\n",
    "\n",
    "\n",
    "                else:\n",
    "                    transformed_popularity[i] = t / (the_first - shift_by)\n",
    "\n",
    "            #print('before: ',sorted(self.tracks_df['popularity'].values,reverse=True))                \n",
    "            #print('after: ', sorted(transformed_popularity,reverse=True))        \n",
    "\n",
    "\n",
    "            return transformed_popularity\n",
    "        except:\n",
    "            if len(sorted_popularity) == 2:\n",
    "                l, s = sorted_popularity\n",
    "\n",
    "                if l <= self.popularity:\n",
    "                    transformed_popularity = (self.tracks_df['popularity'].values - self.popularity) / (self.popularity-s)\n",
    "                elif s >= self.popularity:\n",
    "                    transformed_popularity = (self.tracks_df['popularity'].values - self.popularity) / (l-self.popularity)\n",
    "                    \n",
    "                \n",
    "                else:\n",
    "                    norm_by = max(l-self.popularity, self.popularity-s)\n",
    "                    transformed_popularity = (self.tracks_df['popularity'].values - self.popularity)/ norm_by\n",
    "                    \n",
    "                    \n",
    "                \n",
    "            else:\n",
    "                c = sorted_popularity[0]\n",
    "                if c > self.popularity:\n",
    "                    transformed_popularity =  0.5 * np.ones(self.total_tracks)\n",
    "                elif c < self.popularity: \n",
    "                    transformed_popularity =  -0.5 * np.ones(self.total_tracks)\n",
    "                else:\n",
    "                    transformed_popularity =  np.zeros(self.total_tracks)\n",
    "            return transformed_popularity\n",
    "                    \n",
    "\n",
    "    def transform(self):\n",
    "        return np.hstack((self.transform_track_numbers_(), self.transform_key_(), self.transform_duration_tempo_())), self.transform_features_(), self.transform_labels_()\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_list, song_list = load_files(2014)\n",
    "a = (album_list + song_list)[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a.tracks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 3), (59, 12), (50, 2), (50, 21))"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transform_track_numbers_().shape, a.transform_key_().shape, a.transform_duration_tempo_().shape, a.transform_features_().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.total_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7lZs5r4oQV2nutddffLrg0'"
      ]
     },
     "execution_count": 769,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, a in enumerate((album_list+song_list)):\n",
    "    if np.isnan(a.transform_labels_()).any():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5       ],\n",
       "       [-0.8       ],\n",
       "       [-0.1       ],\n",
       "       [ 1.        ],\n",
       "       [-0.6       ],\n",
       "       [-0.7       ],\n",
       "       [-0.9       ],\n",
       "       [-0.95      ],\n",
       "       [-0.9       ],\n",
       "       [ 0.66666667],\n",
       "       [-0.95      ],\n",
       "       [-1.        ]])"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transform_labels_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_list, song_list = load_files(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TrackNumberTransFormer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-879f2e1acea4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malbum_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-7aa76a4a5aa6>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_track_numbers_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_key_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_duration_tempo_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_features_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_labels_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-7aa76a4a5aa6>\u001b[0m in \u001b[0;36mtransform_track_numbers_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform_track_numbers_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrackNumberTransFormer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracks_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TrackNumberTransFormer' is not defined"
     ]
    }
   ],
   "source": [
    "a = album_list[0]\n",
    "a.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import base\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelectTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self, col_names):\n",
    "        self.col_names = col_names  # We will need these in transform()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # This transformer doesn't need to learn anything about the data,\n",
    "        # so it can just return self without any further processing\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame(X)\n",
    "        return df[self.col_names].values.tolist()\n",
    "        # Return an array with the same number of rows as X and one\n",
    "        # column for each in self.col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58576052, 0.53559871, 0.55825243, 0.7605178 , 0.72977346,\n",
       "       0.69579288, 0.58899676, 0.5420712 , 0.96601942, 0.82847896,\n",
       "       1.        , 0.        ])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cst = ColumnSelectTransformer(['acousticness', 'danceability', 'energy', 'liveness', 'speechiness','valence'])\n",
    "poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "feat_matrix = poly.fit_transform(cst.transform(a.tracks_df))\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaler.fit_transform(feat_matrix)[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyModeTransFormer(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame(X)\n",
    "        key_mode = df[['key',  'mode']].values\n",
    "            \n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        \n",
    "        \n",
    "        return enc.fit_transform(key_mode)\n",
    "        # Return an array with the same number of rows as X and one\n",
    "        # column for each in self.col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackNumberTransFormer(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame(X)\n",
    "        track_index = df.index.values\n",
    "        ar = np.arange(len(track_index)) \n",
    "        g = np.array_split(ar,3)\n",
    "        \n",
    "        d = {}\n",
    "        for i in g[0]:\n",
    "            d[i] = 1\n",
    "        for i in g[1]:\n",
    "            d[i] = 2\n",
    "        for i in g[2]:\n",
    "            d[i] = 3\n",
    "            \n",
    "\n",
    "        into_three = np.array([d[i] for i in track_index]).reshape(-1,1)\n",
    "\n",
    "        \n",
    "        enc = OneHotEncoder(sparse=False,handle_unknown='ignore')\n",
    "        enc.fit_transform(into_three)\n",
    "        \n",
    "        return enc.fit_transform(into_three)\n",
    "        # Return an array with the same number of rows as X and one\n",
    "        # column for each in self.col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_y(album_list, dim_l, dim_n):\n",
    "    \n",
    "    X_n, X_l = np.empty((0,dim_n)), np.empty((0,dim_l))\n",
    "    y = []\n",
    "\n",
    "    for i, a in enumerate(album_list):\n",
    "\n",
    "        if a.total_tracks >=3 and a.total_tracks <= 50:\n",
    "            a_X_n, a_X_l, a_y = a.transform()\n",
    "            X_l = np.vstack(( a_X_l,X_l))\n",
    "            X_n = np.vstack((X_n, a_X_n))\n",
    "            \n",
    "            y = np.hstack((y, a_y))\n",
    "#         else:\n",
    "#             print(i,a.total_tracks,len(a.tracks_df))\n",
    "    return X_l, X_n, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "for year in [2018]:\n",
    "    print(year)\n",
    "    album_list, song_list = load_files(year)\n",
    "    ls += (album_list + song_list)\n",
    "\n",
    "\n",
    "\n",
    "X_l, X_n, y = X_y(ls,28,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8504"
      ]
     },
     "execution_count": 789,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "cv = model_selection.KFold(n_splits=3, random_state=0, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EstimatorTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator # What needs to be done here?\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        #self.estimator.fit(X, y) # Fit the stored estimator.\n",
    "        return self # Question: what should be returned?\n",
    "    \n",
    "    def transform(self, X):\n",
    "        y_predict = self.estimator.predict(X) # Use predict on the stored estimator as a \"transformation\".\n",
    "        return np.array(y_predict).reshape(-1,1) # Be sure to return a 2-D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EstimatorTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-597-afb1f0183f85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m union = FeatureUnion([\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0;34m'nonlinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEstimatorTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonLin_est\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEstimatorTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLin_est\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EstimatorTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "union = FeatureUnion([\n",
    "        ('nonlinear', EstimatorTransformer(nonLin_est)),\n",
    "        ('linear', EstimatorTransformer(Lin_est))\n",
    "    \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  34,   41,   43,   50,   78,   80,   92,   99,  405,  408,  845,\n",
       "        846,  980,  982,  985, 1070, 1075, 1320, 1334, 1583, 1584, 1600,\n",
       "       1614, 1653, 1654])"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isfinite(y).all()\n",
    "np.isnan(y).any()\n",
    "indices = np.arange(len(y)).reshape(-1, 1)\n",
    "indices[np.isnan(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 100}"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lin.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 150}"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonLin.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ],\n",
       "       [-0.01666667],\n",
       "       [-0.2       ],\n",
       "       ...,\n",
       "       [-1.        ],\n",
       "       [-0.8125    ],\n",
       "       [-0.5625    ]])"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 300}"
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lin.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualEstimator(base.BaseEstimator, base.RegressorMixin):\n",
    "    \n",
    "    def __init__(self, linReg, nonLinReg, alpha, max_depth):\n",
    "        self.linReg = linReg\n",
    "        self.alpha = alpha\n",
    "        self.nonLinReg = nonLinReg\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.linReg.set_params(alpha=self.alpha)\n",
    "        self.nonLinReg.set_params(max_depth=self.max_depth)\n",
    "        self.linReg.fit(X, y)\n",
    "        \n",
    "        residual_part = y - self.linReg.predict(X)\n",
    "\n",
    "        self.nonLinReg.fit(X, residual_part)\n",
    "    \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        linear_part = self.linReg.predict(X)\n",
    "        non_linear_part = self.nonLinReg.predict(X)\n",
    "        return linear_part + non_linear_part\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_list, song_list = load_files(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19, 17), (19, 28))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = album_list[0]\n",
    "a.transform()[0].shape,a.transform()[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 7, 6, 5, 3, 8, 2, 0, 1]"
      ]
     },
     "execution_count": 909,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = 2\n",
    "X_l_test, X_n_test, y_test = X_y([album_list[nn]])\n",
    "s = gbr.predict(X_l_test)\n",
    "sorted(range(len(s)), key=lambda k: s[k],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 7, 1, 2, 3, 5, 6, 4, 8])"
      ]
     },
     "execution_count": 910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = album_list[nn]\n",
    "a.tracks_df.sort_values('popularity',ascending=False).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alpha': 0.1, 'max_depth': 5}, -0.13216264297468214)"
      ]
     },
     "execution_count": 932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.best_params_, gbr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=0,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': array([0.1, 0.3, 0.5, 0.7, 0.9]), 'max_depth': [5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr = GridSearchCV(GradientBoostingRegressor(random_state=0),{\"alpha\":np.arange(0.1,1,0.2),\"max_depth\":[5,10]})\n",
    "gbr.fit(X_l,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-849-33bad128a611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResidualEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinReg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonLinReg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"alpha\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"max_depth\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_l\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-832-d0bdab58a284>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mresidual_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinReg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonLinReg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual_part\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 328\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "linReg = Ridge(alpha=10)\n",
    "\n",
    "nonLinReg = RandomForestRegressor(random_state=10,n_estimators=150)\n",
    "\n",
    "re = GridSearchCV(ResidualEstimator(linReg, nonLinReg, 10, 20),{\"alpha\":[30,50,70], \"max_depth\":[20,50,70]})\n",
    "re.fit(X_l,y)\n",
    "\n",
    "\n",
    "  # run each hyperparameter in one of two parallel jobs,scoring='neg_mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 70, 'max_depth': 20}"
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestRegressor(random_state=0,max_depth=10,n_estimators=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlbumPridModel(base.BaseEstimator, base.TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform_(self, y, total):\n",
    "        pass\n",
    "        \n",
    "    def transform(self, X):\n",
    "        pass\n",
    "\n",
    "    def fit_transform(self,X, y=None):\n",
    "        pass\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
